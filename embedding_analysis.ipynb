{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f92a40ed-f08f-4ab7-bfef-7e42633adebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046c4fbe-73e2-414d-9c3f-c87d7cc7eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/stemmler/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406590c-168c-4bc4-8c3d-9e3b2026b51a",
   "metadata": {},
   "source": [
    "# Import ASG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b741b64-e260-479f-aa3a-276fcba5c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████| 992/992 [00:00<00:00, 411kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████| 374M/374M [00:29<00:00, 13.4MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████| 421/421 [00:00<00:00, 749kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████| 152k/152k [00:00<00:00, 1.99MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████| 68.0/68.0 [00:00<00:00, 23.3kB/s]\n",
      "Some weights of the model checkpoint at dracoglacius/NTDB-GPT2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "NTDBGPT2_lm = AutoModelForCausalLM.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_tokenizer = AutoTokenizer.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_embed = GPT2Model.from_pretrained('dracoglacius/NTDB-GPT2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8070eed0-7b7b-4285-8f40-4db17b3df083",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8841c939-9815-43a9-8391-0598924c7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(sequences):\n",
    "    return NTDBGPT2_tokenizer.decode(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0d5318fc-7d78-4163-86e6-c7ca9ba5e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_layer_hidden_embeddings(hidden_states, layer_n=12):\n",
    "    # Default to getting the last layer (12)\n",
    "    \n",
    "    # The start sequence embeddings are in the first tuple element\n",
    "    _start = torch.flatten(hidden_states[0][layer_n], start_dim=-1)\n",
    "    \n",
    "    # The rest of the sequence embeddings are obtained\n",
    "    _hs = [x[layer_n] for x in hidden_states[1:]]\n",
    "    _hs = torch.concat(_hs, dim=1)\n",
    "    \n",
    "    return torch.concat([_start, _hs], dim=1).squeeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897499a7-0607-47d6-96a0-c0d3b493a945",
   "metadata": {},
   "source": [
    "# Testing Scenario Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "667ad2f5-9dc9-4bcf-b5b7-7a0f07affef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_ECODES = ['E885.9','E812.0','E966.0']\n",
    "\n",
    "ecode_key = SEARCH_ECODES[0]\n",
    "\n",
    "input_seq = f\"<START> {ecode_key} <DSTART>\"\n",
    "\n",
    "seq_ids = NTDBGPT2_tokenizer.encode(input_seq, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc1e1a6-502d-4758-84dd-ee2c2b399357",
   "metadata": {},
   "source": [
    "#### Generate Scenario from Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "72a27bcf-ef48-44cc-9c82-7208d963681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_wft = NTDBGPT2_lm.generate(\n",
    "    seq_ids, \n",
    "    do_sample=True,\n",
    "    min_length=10,\n",
    "    max_length=12,\n",
    "    #top_p=0.9, \n",
    "    top_k=0,\n",
    "    return_dict_in_generate=True,\n",
    "    forced_eos_token_id=NTDBGPT2_tokenizer.eos_token_id,\n",
    "    #repetition_penalty=3.0,\n",
    "    #length_penalty=1.0,\n",
    "    #num_return_seqs=1,\n",
    "    output_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9b2af91b-ae35-4891-adb0-d716947a6dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   9,   1,  18,  25,   3, 919,  24,   4,   5,   2]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_wft.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3239c5cf-426e-4633-9061-dd139f7c1868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_wft.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9effd33b-809c-4575-acc3-d83aa5efe8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> E885.9 <DSTART> 805.4 805.2 <PSTART> 81.66 88.26 88.38 87.03 <END>'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(out_wft.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ff9e01bd-3cc2-4501-a843-c6bce726409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = get_n_layer_hidden_embeddings(out_wft.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "231c8236-3f3e-4193-b133-f4ab1476a0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3cc2d-85ab-4d91-9d9c-4877e3c97d28",
   "metadata": {},
   "source": [
    "#### Shape Discrepency\n",
    "\n",
    "`<END>` is being treated as `eos` and therefore the output is ignored. The final token's value is therefore thought to contain the \"best\" representation of the whole sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "00ba4c26-7958-4df3-a234-fdc30dd49aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6226,  0.1586, -0.0762,  ...,  0.3346,  0.4395, -0.2872],\n",
       "        [ 0.1316, -0.3097, -0.6136,  ..., -0.1229,  0.0251,  0.0816],\n",
       "        [ 0.0113, -0.5432, -1.4481,  ..., -0.1895,  0.4446,  0.2490],\n",
       "        ...,\n",
       "        [ 0.6987,  0.1755, -0.5157,  ...,  0.0493, -0.4683, -0.3290],\n",
       "        [ 0.7893,  0.2013, -0.4699,  ..., -0.0489, -0.4174, -0.2398],\n",
       "        [ 1.0890,  0.3541, -0.3962,  ..., -0.2973, -0.5481, -0.1599]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9cdf1153-49b5-4966-9d14-7023382525ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6226,  0.1586, -0.0762,  ...,  0.3346,  0.4395, -0.2872],\n",
       "        [ 0.1316, -0.3097, -0.6136,  ..., -0.1229,  0.0251,  0.0816],\n",
       "        [ 0.0113, -0.5432, -1.4481,  ..., -0.1895,  0.4446,  0.2490],\n",
       "        [ 0.5896, -1.0609, -0.2501,  ...,  0.1293,  0.2424, -0.3202],\n",
       "        [ 0.5839, -0.6312,  0.1603,  ...,  0.2545,  0.4496, -0.2992]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5dbd86b9-57ec-4318-8799-1c73dfe46a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5158f1-aa9d-457e-9f72-da03d3faff2c",
   "metadata": {},
   "source": [
    "#### Generate Second Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "251fb6ca-377c-4597-a41c-dcd633641c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_wft2 = NTDBGPT2_lm.generate(\n",
    "    NTDBGPT2_tokenizer.encode('<START> E885.9', return_tensors='pt'), \n",
    "    do_sample=True,\n",
    "    min_length=10,\n",
    "    max_length=12,\n",
    "    #top_p=0.9, \n",
    "    top_k=0,\n",
    "    return_dict_in_generate=True,\n",
    "    forced_eos_token_id=NTDBGPT2_tokenizer.eos_token_id,\n",
    "    #repetition_penalty=3.0,\n",
    "    #length_penalty=1.0,\n",
    "    #num_return_seqs=1,\n",
    "    output_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6412528a-e96c-4186-b5be-e75dc984d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> E885.9 <DSTART> 958.4 860 807.04 <PSTART> 88.38 93.23 88.77 99.04 <END>'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(out_wft2.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "97ba9418-d85c-4b16-b08e-9c1df0d0fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "em2 = get_n_layer_hidden_embeddings(out_wft2.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5954f3a9-302e-4e7a-b6aa-998d7aa4b4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6226,  0.1586, -0.0762,  ...,  0.3346,  0.4395, -0.2872],\n",
       "        [ 0.1316, -0.3097, -0.6136,  ..., -0.1229,  0.0251,  0.0816],\n",
       "        [ 0.0114, -0.5432, -1.4481,  ..., -0.1895,  0.4446,  0.2490],\n",
       "        ...,\n",
       "        [ 0.4292, -0.2142, -0.6003,  ...,  0.0190, -0.6618, -0.4300],\n",
       "        [ 0.0876, -0.0530, -0.2207,  ...,  0.0445, -0.8208, -0.4123],\n",
       "        [ 0.1489,  0.2430, -0.7810,  ...,  0.0136, -0.6779, -0.3698]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3043251d-6da4-445f-9dc0-5c38867063d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6226,  0.1586, -0.0762,  ...,  0.3346,  0.4395, -0.2872],\n",
       "        [ 0.1316, -0.3097, -0.6136,  ..., -0.1229,  0.0251,  0.0816],\n",
       "        [ 0.0114, -0.5432, -1.4481,  ..., -0.1895,  0.4446,  0.2490],\n",
       "        [ 0.2790, -0.7283, -1.2843,  ...,  0.1576,  0.8097,  0.1383],\n",
       "        [ 0.9445, -0.2814, -1.3363,  ..., -0.4390,  0.0595, -0.1846]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2776f77a-5263-42da-93ef-b08bbbe271c8",
   "metadata": {},
   "source": [
    "## Assess Using Cosine Similarity\n",
    "\n",
    "* Sequence 1: `<START> E885.9 <DSTART> 805.4 805.2 <PSTART> 81.66 88.26 88.38 87.03 <END>`\n",
    "* Sequence 2: `<START> E885.9 <DSTART> 958.4 860 807.04 <PSTART> 88.38 93.23 88.77 99.04 <END>`\n",
    "\n",
    "#### Observations\n",
    "\n",
    "* Only the first three tokens overlap.\n",
    "* Therefore using cosine similarity, we expect only the first three tokens to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7c20a942-7ec7-4cc6-bfad-fdb95ecb9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "7141335b-fc2e-4eb2-89c4-268d16b9ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 0.6948, 0.4636])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(em[:5,:], em2[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56c0090-ba70-4854-9318-7582bed5b993",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "* As we thought, only the first three tokens are perfectly aligned.\n",
    "* Diagnostic codes are not considered very similar\n",
    "* Diagnostic code and `<PSTART>` is considered to be very dissimilar\n",
    "* However `<PSTART>` and the first procedure code is considered similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e7ff1591-c389-4cea-9c74-e7751f2e216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0000,  1.0000,  0.6948,  0.4636, -0.5227,  0.9388,  0.9521,\n",
       "         0.9006,  0.9390])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos(em[:10,:], em2[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173b071-2cde-4f33-bfeb-82551452b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
