{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1139438f-730e-4c3a-8ca6-3c8c64f9cc76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Model\n",
      "File \u001b[0;32m~/anaconda3/envs/stemmler/lib/python3.8/site-packages/torch/__init__.py:231\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m)\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# issue 38137 and python issue 43367. Submodules of a C extension are\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# non-standard, and attributes of those submodules cannot be pickled since\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# pickle expect to be able to import them as \"from _C.sub import attr\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# which fails with \"_C is not a package\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2Model\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f8550-6e4f-45a0-bb3a-e4544516d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NTDBGPT2_lm = AutoModelForCausalLM.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_tokenizer = AutoTokenizer.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_embed = GPT2Model.from_pretrained('dracoglacius/NTDB-GPT2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701802e-a336-48ff-a2f7-aae12aea8332",
   "metadata": {},
   "source": [
    "## ECodes\n",
    "\n",
    "* E812.0 = Other motor vehicle traffic accident involving collision with motor vehicle injuring driver of motor vehicle other than motorcycle.\n",
    "* E885.9 = Accidental fall from other slipping tripping or stumbling\n",
    "* E966.0 = Assault by cutting and piercing instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc35ad-b7fd-416f-beb7-de7304876012",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#e8120_top_seq = []\n",
    "#e8120_top_dsc = []\n",
    "#with open(\"./data/E8120_top_50_gen.txt\") as f:\n",
    "#    while True:\n",
    "#        line1 = f.readline()\n",
    "#        line2 = f.readline()\n",
    "#        if not line2: break \n",
    "#        e8120_top_seq.append(eval(line1))\n",
    "#        e8120_top_dsc.append(eval(line2))\n",
    "#    \n",
    "#e8120_bot_seq = []\n",
    "#e8120_bot_dsc = []\n",
    "#with open(\"./data/E8120_bot_50_gen.txt\") as f:\n",
    "#    while True:\n",
    "#        line1 = f.readline()\n",
    "#        line2 = f.readline()\n",
    "#        if not line2: break \n",
    "#        e8120_bot_seq.append(eval(line1))\n",
    "#        e8120_bot_dsc.append(eval(line2))\n",
    "#    \n",
    "#e8859_top_seq = []\n",
    "#e8859_top_dsc = []\n",
    "#with open(\"./data/E8859_top_50_gen.txt\") as f:\n",
    "#    while True:\n",
    "#        line1 = f.readline()\n",
    "#        line2 = f.readline()\n",
    "#        if not line2: break \n",
    "#        e8859_top_seq.append(eval(line1))\n",
    "#        e8859_top_dsc.append(eval(line2))\n",
    "#    \n",
    "#e8859_bot_seq = []\n",
    "#e8859_bot_dsc = []\n",
    "#with open(\"./data/E8859_bot_50_gen.txt\") as f:\n",
    "#    while True:\n",
    "#        line1 = f.readline()\n",
    "#        line2 = f.readline()\n",
    "#        if not line2: break \n",
    "#        e8859_bot_seq.append(eval(line1))\n",
    "#        e8859_bot_dsc.append(eval(line2))\n",
    "#    \n",
    "#e9660_top_seq = []\n",
    "#e9660_top_dsc = []\n",
    "#with open(\"./data/E9660_top_50_gen.txt\") as f:\n",
    "#    while True:\n",
    "#        line1 = f.readline()\n",
    "#        line2 = f.readline()\n",
    "#        if not line2: break \n",
    "#        e9660_top_seq.append(eval(line1))\n",
    "#        e9660_top_dsc.append(eval(line2))\n",
    "#    \n",
    "#e9660_bot_seq = []\n",
    "#e9660_bot_dsc = []\n",
    "#with open(\"./data/E9660_bot_50_gen.txt\") as f:\n",
    "#   while True:\n",
    "#       line1 = f.readline()\n",
    "#       line2 = f.readline()\n",
    "#       if not line2: break \n",
    "#       e9660_bot_seq.append(eval(line1))\n",
    "#       e9660_bot_dsc.append(eval(line2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de72c4-a4ea-44d3-bc7c-5df62741ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seq = np.load(\"./data/25k_train_seqs_3_22_E8859_E8120_E9660_E9654_E9240.npy\")\n",
    "gen_seq = np.load(\"./data/25k_gen_seqs_3_22_E8859_E8120_E9660_E9654_E9240.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0f6ae-ad6e-48b9-b169-dab988621c27",
   "metadata": {},
   "source": [
    "## Separate Data\n",
    "\n",
    "#### Training Data is In Domain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f41527-a019-4dab-8c32-af4906626a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_trn_seq = [x for x in trn_seq if 'E812.0' in x] # 5000 items\n",
    "e8859_trn_seq = [x for x in trn_seq if 'E885.9' in x] # 5000 items\n",
    "e9660_trn_seq = [x for x in trn_seq if 'E966.0' in x] # 5000 items\n",
    "e9654_trn_seq = [x for x in trn_seq if 'E965.4' in x] # 5000 items\n",
    "e9240_trn_seq = [x for x in trn_seq if 'E924.0' in x] # 5000 items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22479c34-baaf-4e22-a52e-dc3add7e6012",
   "metadata": {},
   "source": [
    "#### Generated Data is Out of Domain (OOD) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c7335-2ae9-480e-93bc-9d590edb8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_gen_seq = [x for x in gen_seq if 'E812.0' in x] # 5000 items\n",
    "e8859_gen_seq = [x for x in gen_seq if 'E885.9' in x] # 5000 items\n",
    "e9660_gen_seq = [x for x in gen_seq if 'E966.0' in x] # 5000 items\n",
    "e9654_gen_seq = [x for x in gen_seq if 'E965.4' in x] # 5000 items\n",
    "e9240_gen_seq = [x for x in gen_seq if 'E924.0' in x] # 5000 items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc96f2f-750d-4c1b-9f2a-19858a4918ca",
   "metadata": {},
   "source": [
    "We have the intuition that given a distribution with center of the hyper-elliposid $c$ and the shape of the ellipsoid defined by $\\Sigma$, $c$ and $\\sigma$ should not deviate from the empirical mean ($\\hat{c}$) and the covariance estimations ($\\hat{\\Sigma}$) taken from the training data. \n",
    "\n",
    "To obtain these estimates we need to:\n",
    "\n",
    "1. Feed the NTDB model with the training data (length $n$) and from the last token get the features of each layer ($n$ x 13 x 768)\n",
    "1. Calculate the sample mean ($\\hat{c}$) and the covariance estimate ($\\hat{\\Sigma}$), while also getting the estimated pseudo-inverse (called `.precision_` in sklearn)\n",
    "\n",
    "To obtain the OOD estimation we need to:\n",
    "\n",
    "1. Calculate the Mahalanobis Distance Feature (MDF) using the generated data (should be a vector equal to the number of layers)\n",
    "1. Calculate the Anomaly Score\n",
    "  1. This is a one-class SVM with a linear kernel with MDF as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40579530-3011-444a-a0a5-be932b66dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_embeddings(hidden_states, is_train=True, use_last=True):\n",
    "    if is_train:\n",
    "        \"\"\"\n",
    "        The first hidden_state contains the whole sequence\n",
    "        \"\"\"\n",
    "        _em = torch.squeeze(torch.stack(hidden_states[0]).transpose(0,2), dim=1)\n",
    "    else:\n",
    "        _start = torch.squeeze(torch.stack(hidden_states[0]).transpose(0,2), dim=1)\n",
    "        _hs = torch.stack([torch.reshape(torch.stack(x), [13, 768]) for x in hidden_states[1:]])\n",
    "        _em = torch.concat([_start, _hs])\n",
    "        \n",
    "    if use_last:\n",
    "        return _em[-1, :, :]\n",
    "    else:\n",
    "        return _em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64c7b4-7846-4952-ac28-5bb55b9830bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sequences, is_train=True, use_last=True):\n",
    "    token_layer_embeddings = []\n",
    "    for seq in tqdm.tqdm(sequences):\n",
    "        seq_ids = NTDBGPT2_tokenizer.encode(seq, return_tensors='pt')\n",
    "        if len(seq_ids[0]) > 19:\n",
    "            continue\n",
    "        out = NTDBGPT2_lm.generate(\n",
    "            seq_ids,\n",
    "            do_sample=True,\n",
    "            #min_length=10,\n",
    "            #max_length=12,\n",
    "            #top_p=0.9, \n",
    "            top_k=0,\n",
    "            return_dict_in_generate=True,\n",
    "            forced_eos_token_id=NTDBGPT2_tokenizer.eos_token_id,\n",
    "            #repetition_penalty=3.0,\n",
    "            #length_penalty=1.0,\n",
    "            #num_return_seqs=1,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        token_layer_embeddings.append(get_hidden_embeddings(out.hidden_states, is_train, use_last))\n",
    "    if use_last:\n",
    "        return torch.stack(token_layer_embeddings)\n",
    "    else:\n",
    "        return token_layer_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936027a3-db02-4574-88c5-5ddd88074f0e",
   "metadata": {},
   "source": [
    "#### Get Sequence Embeddings of All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f674a6-4061-469f-a09f-59618da833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_seq(seq):\n",
    "    return ' '.join(x for x in seq.split() if x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39754f-62cb-4708-b7c2-76a2e36c048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_trn_all_token_layer_embeddings = get_embeddings(e8120_trn_seq, use_last=False)\n",
    "e8120_gen_all_token_layer_embeddings = get_embeddings(e8120_gen_seq, use_last=False)\n",
    "np.save(\"./outputs/e8120_trn_all_em.npy\", e8120_trn_all_token_layer_embeddings)\n",
    "np.save(\"./outputs/e8120_gen_all_em.npy\", e8120_gen_all_token_layer_embeddings)\n",
    "e8120_trn_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e8120_trn_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e8120_trn_end_em.npy\", e8120_trn_end_token_layer_embeddings)\n",
    "e8120_gen_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e8120_gen_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e8120_gen_end_em.npy\", e8120_gen_end_token_layer_embeddings)\n",
    "\n",
    "del e8120_trn_all_token_layer_embeddings\n",
    "del e8120_gen_all_token_layer_embeddings\n",
    "del e8120_trn_end_token_layer_embeddings\n",
    "del e8120_gen_end_token_layer_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d25285-f2ca-4b6f-9fe2-a2d4cd253974",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8859_trn_all_token_layer_embeddings = get_embeddings(e8859_trn_seq, use_last=False)\n",
    "e8859_gen_all_token_layer_embeddings = get_embeddings(e8859_gen_seq, use_last=False)\n",
    "np.save(\"./outputs/e8859_trn_all_em.npy\", e8859_trn_all_token_layer_embeddings)\n",
    "np.save(\"./outputs/e8859_gen_all_em.npy\", e8859_gen_all_token_layer_embeddings)\n",
    "e8859_trn_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e8859_trn_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e8859_trn_end_em.npy\", e8859_trn_end_token_layer_embeddings)\n",
    "e8859_gen_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e8859_gen_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e8859_gen_end_em.npy\", e8859_gen_end_token_layer_embeddings)\n",
    "\n",
    "del e8859_trn_all_token_layer_embeddings\n",
    "del e8859_gen_all_token_layer_embeddings\n",
    "del e8859_trn_end_token_layer_embeddings\n",
    "del e8859_gen_end_token_layer_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63dabc-0d02-4c49-8704-c2e475941ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e9660_trn_all_token_layer_embeddings = get_embeddings(e9660_trn_seq, use_last=False)\n",
    "e9660_gen_all_token_layer_embeddings = get_embeddings(e9660_gen_seq, use_last=False)\n",
    "np.save(\"./outputs/e9660_trn_all_em.npy\", e9660_trn_all_token_layer_embeddings)\n",
    "np.save(\"./outputs/e9660_gen_all_em.npy\", e9660_gen_all_token_layer_embeddings)\n",
    "e9660_trn_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9660_trn_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9660_trn_end_em.npy\", e9660_trn_end_token_layer_embeddings)\n",
    "e9660_gen_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9660_gen_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9660_gen_end_em.npy\", e9660_gen_end_token_layer_embeddings)\n",
    "\n",
    "del e9660_trn_all_token_layer_embeddings\n",
    "del e9660_gen_all_token_layer_embeddings\n",
    "del e9660_trn_end_token_layer_embeddings\n",
    "del e9660_gen_end_token_layer_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ffeb34-bf27-44b0-8be3-9cd59f1128b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e9654_trn_all_token_layer_embeddings = get_embeddings(e9654_trn_seq, use_last=False)\n",
    "e9654_gen_all_token_layer_embeddings = get_embeddings(e9654_gen_seq, use_last=False)\n",
    "np.save(\"./outputs/e9654_trn_all_em.npy\", e9654_trn_all_token_layer_embeddings)\n",
    "np.save(\"./outputs/e9654_gen_all_em.npy\", e9654_gen_all_token_layer_embeddings)\n",
    "e9654_trn_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9654_trn_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9654_trn_end_em.npy\", e9654_trn_end_token_layer_embeddings)\n",
    "e9654_gen_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9654_gen_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9654_gen_end_em.npy\", e9654_gen_end_token_layer_embeddings)\n",
    "\n",
    "del e9654_trn_all_token_layer_embeddings\n",
    "del e9654_gen_all_token_layer_embeddings\n",
    "del e9654_trn_end_token_layer_embeddings\n",
    "del e9654_gen_end_token_layer_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100f1e6-18b5-4b32-88aa-dc99bf42714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e9240_trn_all_token_layer_embeddings = get_embeddings(e9240_trn_seq, use_last=False)\n",
    "e9240_gen_all_token_layer_embeddings = get_embeddings(e9240_gen_seq, use_last=False)\n",
    "np.save(\"./outputs/e9240_trn_all_em.npy\", e9240_trn_all_token_layer_embeddings)\n",
    "np.save(\"./outputs/e9240_gen_all_em.npy\", e9240_gen_all_token_layer_embeddings)\n",
    "e9240_trn_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9240_trn_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9240_trn_end_em.npy\", e9240_trn_end_token_layer_embeddings)\n",
    "e9240_gen_end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in e9240_gen_all_token_layer_embeddings])\n",
    "np.save(\"./outputs/e9240_gen_end_em.npy\", e9240_gen_end_token_layer_embeddings)\n",
    "\n",
    "del e9240_trn_all_token_layer_embeddings\n",
    "del e9240_gen_all_token_layer_embeddings\n",
    "del e9240_trn_end_token_layer_embeddings\n",
    "del e9240_gen_end_token_layer_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704432fb-30c2-4aca-9ce0-049e40aaa809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
