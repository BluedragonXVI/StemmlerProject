{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1139438f-730e-4c3a-8ca6-3c8c64f9cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/envs/stemmler/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPT2Model\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de645602-3561-49ac-b666-2ebe2392db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icd9cms.icd9 import search\n",
    "import pickle\n",
    "with open(\"./data/pcode_dict.txt\", \"rb\") as fp: \n",
    "    icd9_pcode_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cf8664f-d675-4eb3-bf5e-468b7be7d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_seq_dsc(seq):\n",
    "    cds = seq.split()\n",
    "    tp = 'START'\n",
    "    for c in cds:\n",
    "        if c == '<START>':\n",
    "            print('=' * 9 + ' START ' + '=' * 9)\n",
    "        elif c == '<DSTART>':\n",
    "            tp = 'DX'\n",
    "            print('=' * 10 + ' DXS ' + '=' * 10)\n",
    "        elif c == '<PSTART>':\n",
    "            tp = 'PR'\n",
    "            print('=' * 10 + ' PRS ' + '=' * 10)\n",
    "        elif c == '<END>':\n",
    "            print('=' * 10 + ' END ' + '=' * 10)\n",
    "        elif c == '<UNK>':\n",
    "            print(f'{c}:Unknown Code')\n",
    "        else:\n",
    "            if tp == 'DX':\n",
    "                d = search(c)\n",
    "                if d:\n",
    "                    print(d)\n",
    "            if tp == 'PR':\n",
    "                pr_cd = re.sub(r'\\.', '', c)\n",
    "                if pr_cd in icd9_pcode_dict:\n",
    "                    print(f\"{pr_cd}:{icd9_pcode_dict[pr_cd]}\")\n",
    "                else:\n",
    "                    print(f'{pr_cd}:Unknown Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1f8550-6e4f-45a0-bb3a-e4544516d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dracoglacius/NTDB-GPT2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "NTDBGPT2_lm = AutoModelForCausalLM.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_tokenizer = AutoTokenizer.from_pretrained('dracoglacius/NTDB-GPT2')\n",
    "NTDBGPT2_embed = GPT2Model.from_pretrained('dracoglacius/NTDB-GPT2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701802e-a336-48ff-a2f7-aae12aea8332",
   "metadata": {},
   "source": [
    "## ECodes\n",
    "\n",
    "* E812.0 = Other motor vehicle traffic accident involving collision with motor vehicle injuring driver of motor vehicle other than motorcycle.\n",
    "* E885.9 = Accidental fall from other slipping tripping or stumbling\n",
    "* E966.0 = Assault by cutting and piercing instrument\n",
    "* E965.4 = Assault-firearm NEC:Assault by other and unspecified firearm\n",
    "* E924.0 = Acc-hot liquid & steam - Accident caused by hot liquids and vapors, including steam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5462f-1ba1-45c4-9af5-32b8009ef380",
   "metadata": {},
   "source": [
    "# Adversarial Examples\n",
    "\n",
    "* E812.0 = Other motor vehicle traffic accident involving collision with motor vehicle injuring driver of motor vehicle other than motorcycle.\n",
    "* E965.4 = Assault-firearm NEC:Assault by other and unspecified firearm\n",
    "* E924.0 = Acc-hot liquid & steam - Accident caused by hot liquids and vapors, including steam\n",
    "\n",
    "1. From the training set obtain the ECode and DCodes for E812.0, E965.4, and E924.0\n",
    "1. Create 6 sets by mixing the stem and procedure combinations\n",
    "1. Exclude sets with total token length > 20\n",
    "1. Create embeddings\n",
    "\n",
    "* We count these as adversarial example since the stems and procedures themselves come from the training data\n",
    "* The question is whether the OOD classifier can identify them as OOD based on the sequential information learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23de72c4-a4ea-44d3-bc7c-5df62741ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_seq = np.load(\"./data/25k_train_seqs_3_22_E8859_E8120_E9660_E9654_E9240.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0f6ae-ad6e-48b9-b169-dab988621c27",
   "metadata": {},
   "source": [
    "## Separate Data\n",
    "\n",
    "#### Training Data is In Domain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f41527-a019-4dab-8c32-af4906626a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_trn_seq = [x for x in trn_seq if 'E812.0' in x] # 5000 items\n",
    "e9654_trn_seq = [x for x in trn_seq if 'E965.4' in x] # 5000 items\n",
    "e9240_trn_seq = [x for x in trn_seq if 'E924.0' in x] # 5000 items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994911e6-ef6c-4471-982c-90cefc8c85d4",
   "metadata": {},
   "source": [
    "#### Adversarial Data\n",
    "\n",
    "* Stemm: E812.0 + Procedures: E965.4\n",
    "* Stemm: E812.0 + Procedures: E924.0\n",
    "* Stemm: E965.4 + Procedures: E812.0\n",
    "* Stemm: E965.4 + Procedures: E924.0\n",
    "* Stemm: E924.0 + Procedures: E812.0\n",
    "* Stemm: E924.0 + Procedures: E965.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c875d535-f0d7-4320-b93f-52574b648519",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_trn_stem = [x.split('<PSTART>')[0] for x in e8120_trn_seq]\n",
    "e8120_trn_prcs = [x.split('<PSTART>')[1] for x in e8120_trn_seq]\n",
    "\n",
    "e9654_trn_stem = [x.split('<PSTART>')[0] for x in e9654_trn_seq]\n",
    "e9654_trn_prcs = [x.split('<PSTART>')[1] for x in e9654_trn_seq]\n",
    "\n",
    "e9240_trn_stem = [x.split('<PSTART>')[0] for x in e9240_trn_seq]\n",
    "e9240_trn_prcs = [x.split('<PSTART>')[1] for x in e9240_trn_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71bf3262-9a17-43c4-9598-34516a6af2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e8120_e9654_adv_seq = [s + '<PSTART>' + p for s,p in zip(e8120_trn_stem, e9654_trn_prcs)]\n",
    "e8120_e9240_adv_seq = [s + '<PSTART>' + p for s,p in zip(e8120_trn_stem, e9240_trn_prcs)]\n",
    "e9654_e8120_adv_seq = [s + '<PSTART>' + p for s,p in zip(e9654_trn_stem, e8120_trn_prcs)]\n",
    "e9654_e9240_adv_seq = [s + '<PSTART>' + p for s,p in zip(e9654_trn_stem, e9240_trn_prcs)]\n",
    "e9240_e8120_adv_seq = [s + '<PSTART>' + p for s,p in zip(e9240_trn_stem, e8120_trn_prcs)]\n",
    "e9240_e9654_adv_seq = [s + '<PSTART>' + p for s,p in zip(e9240_trn_stem, e9654_trn_prcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40579530-3011-444a-a0a5-be932b66dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_embeddings(hidden_states, is_train=True, use_last=True):\n",
    "    if is_train:\n",
    "        \"\"\"\n",
    "        The first hidden_state contains the whole sequence\n",
    "        \"\"\"\n",
    "        _em = torch.squeeze(torch.stack(hidden_states[0]).transpose(0,2), dim=1)\n",
    "    else:\n",
    "        _start = torch.squeeze(torch.stack(hidden_states[0]).transpose(0,2), dim=1)\n",
    "        _hs = torch.stack([torch.reshape(torch.stack(x), [13, 768]) for x in hidden_states[1:]])\n",
    "        _em = torch.concat([_start, _hs])\n",
    "        \n",
    "    if use_last:\n",
    "        return _em[-1, :, :]\n",
    "    else:\n",
    "        return _em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff64c7b4-7846-4952-ac28-5bb55b9830bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sequences, is_train=True, use_last=True):\n",
    "    token_layer_embeddings = []\n",
    "    for seq in tqdm.tqdm(sequences):\n",
    "        seq_ids = NTDBGPT2_tokenizer.encode(seq, return_tensors='pt')\n",
    "        if len(seq_ids[0]) > 19:\n",
    "            continue\n",
    "        out = NTDBGPT2_lm.generate(\n",
    "            seq_ids,\n",
    "            do_sample=True,\n",
    "            #min_length=10,\n",
    "            #max_length=12,\n",
    "            #top_p=0.9, \n",
    "            top_k=0,\n",
    "            return_dict_in_generate=True,\n",
    "            forced_eos_token_id=NTDBGPT2_tokenizer.eos_token_id,\n",
    "            #repetition_penalty=3.0,\n",
    "            #length_penalty=1.0,\n",
    "            #num_return_seqs=1,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        token_layer_embeddings.append(get_hidden_embeddings(out.hidden_states, is_train, use_last))\n",
    "    if use_last:\n",
    "        return torch.stack(token_layer_embeddings)\n",
    "    else:\n",
    "        return token_layer_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936027a3-db02-4574-88c5-5ddd88074f0e",
   "metadata": {},
   "source": [
    "#### Get Sequence Embeddings of All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41f674a6-4061-469f-a09f-59618da833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_seq(seq):\n",
    "    return ' '.join(x for x in seq.split() if x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "971e2154-574e-44b3-834d-fd236aa5560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_embedding_data(ecode1, ecode2, seqs):\n",
    "    _all_token_layer_embeddings = get_embeddings(seqs, use_last=False)\n",
    "    np.save(f\"./outputs/{ecode1}_{ecode2}_adv_all_em.npy\", _all_token_layer_embeddings)\n",
    "    _end_token_layer_embeddings = torch.stack([x[-1,:,:] for x in _all_token_layer_embeddings])\n",
    "    np.save(f\"./outputs/{ecode1}_{ecode2}_adv_end_em.npy\", _end_token_layer_embeddings)\n",
    "\n",
    "    del _all_token_layer_embeddings\n",
    "    del _end_token_layer_embeddings\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdf82121-f10a-4820-9b48-374ce282d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [10:36<00:00,  7.85it/s]\n",
      "/home/paul/anaconda3/envs/stemmler/lib/python3.8/site-packages/numpy/lib/npyio.py:528: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/paul/anaconda3/envs/stemmler/lib/python3.8/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [12:58<00:00,  6.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [12:22<00:00,  6.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [14:20<00:00,  5.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [12:16<00:00,  6.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [11:35<00:00,  7.19it/s]\n"
     ]
    }
   ],
   "source": [
    "create_adversarial_embedding_data('e8120', 'e9654', e8120_e9654_adv_seq)\n",
    "create_adversarial_embedding_data('e8120', 'e9240', e8120_e9240_adv_seq)\n",
    "create_adversarial_embedding_data('e9654', 'e8120', e9654_e8120_adv_seq)\n",
    "create_adversarial_embedding_data('e9654', 'e9240', e9654_e9240_adv_seq)\n",
    "create_adversarial_embedding_data('e9240', 'e8120', e9240_e8120_adv_seq)\n",
    "create_adversarial_embedding_data('e9240', 'e9654', e9240_e9654_adv_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "704432fb-30c2-4aca-9ce0-049e40aaa809",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('outputs/e8120_e9654_adv_seq.npy', e8120_e9654_adv_seq)\n",
    "np.save('outputs/e8120_e9240_adv_seq.npy', e8120_e9240_adv_seq)\n",
    "np.save('outputs/e9654_e8120_adv_seq.npy', e9654_e8120_adv_seq)\n",
    "np.save('outputs/e9654_e9240_adv_seq.npy', e9654_e9240_adv_seq)\n",
    "np.save('outputs/e9240_e8120_adv_seq.npy', e9240_e8120_adv_seq)\n",
    "np.save('outputs/e9240_e9654_adv_seq.npy', e9240_e9654_adv_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a8702-d53e-4064-856e-a644ce539f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
